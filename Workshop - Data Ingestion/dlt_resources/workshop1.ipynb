{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrTFv5nPClXh"
      },
      "source": [
        "# **Homework**: Data talks club data engineering zoomcamp Data loading workshop\n",
        "\n",
        "Hello folks, let's practice what we learned - Loading data with the best practices of data engineering.\n",
        "\n",
        "Here are the exercises we will do\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLF4iXf-NR7t"
      },
      "source": [
        "# 1. Use a generator\n",
        "\n",
        "Remember the concept of generator? Let's practice using them to futher our understanding of how they work.\n",
        "\n",
        "Let's define a generator and then run it as practice.\n",
        "\n",
        "**Answer the following questions:**\n",
        "\n",
        "- **Question 1: What is the sum of the outputs of the generator for limit = 5?**\n",
        "- **Question 2: What is the 13th number yielded**\n",
        "\n",
        "I suggest practicing these questions without GPT as the purpose is to further your learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLng-bDJN4jf",
        "outputId": "547683cb-5f56-4815-a903-d0d9578eb1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.382332347441762\n"
          ]
        }
      ],
      "source": [
        "def square_root_generator(limit):\n",
        "    n = 1\n",
        "    while n <= limit:\n",
        "        yield n ** 0.5\n",
        "        n += 1\n",
        "\n",
        "# Example usage:\n",
        "limit = 5\n",
        "generator = square_root_generator(limit)\n",
        "\n",
        "##modyfing the code to get the answer for q1\n",
        "\n",
        "number = []\n",
        "for sqrt_value in generator:\n",
        "    number.append((sqrt_value))\n",
        "\n",
        "print(sum(number))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbe3q55zN43j"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.605551275463989\n"
          ]
        }
      ],
      "source": [
        "#question 2\n",
        "\n",
        "def square_root_generator(limit):\n",
        "    n = 1\n",
        "    while n <= limit:\n",
        "        yield n ** 0.5\n",
        "        n += 1\n",
        "\n",
        "# Example usage:\n",
        "limit = 13\n",
        "generator = square_root_generator(limit)\n",
        "\n",
        "##modyfing the code to get the answer for q1\n",
        "\n",
        "number = []\n",
        "for sqrt_value in generator:\n",
        "    number.append((sqrt_value))\n",
        "\n",
        "print(number[12])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjWhILzGJMpK"
      },
      "source": [
        "# 2. Append a generator to a table with existing data\n",
        "\n",
        "\n",
        "Below you have 2 generators. You will be tasked to load them to duckdb and answer some questions from the data\n",
        "\n",
        "1. Load the first generator and calculate the sum of ages of all people. Make sure to only load it once.\n",
        "2. Append the second generator to the same table as the first.\n",
        "3. **After correctly appending the data, calculate the sum of all ages of people.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ID': 1, 'Name': 'Person_1', 'Age': 26, 'City': 'City_A'}\n",
            "{'ID': 2, 'Name': 'Person_2', 'Age': 27, 'City': 'City_A'}\n",
            "{'ID': 3, 'Name': 'Person_3', 'Age': 28, 'City': 'City_A'}\n",
            "{'ID': 4, 'Name': 'Person_4', 'Age': 29, 'City': 'City_A'}\n",
            "{'ID': 5, 'Name': 'Person_5', 'Age': 30, 'City': 'City_A'}\n",
            "{'ID': 3, 'Name': 'Person_3', 'Age': 33, 'City': 'City_B', 'Occupation': 'Job_3'}\n",
            "{'ID': 4, 'Name': 'Person_4', 'Age': 34, 'City': 'City_B', 'Occupation': 'Job_4'}\n",
            "{'ID': 5, 'Name': 'Person_5', 'Age': 35, 'City': 'City_B', 'Occupation': 'Job_5'}\n",
            "{'ID': 6, 'Name': 'Person_6', 'Age': 36, 'City': 'City_B', 'Occupation': 'Job_6'}\n",
            "{'ID': 7, 'Name': 'Person_7', 'Age': 37, 'City': 'City_B', 'Occupation': 'Job_7'}\n",
            "{'ID': 8, 'Name': 'Person_8', 'Age': 38, 'City': 'City_B', 'Occupation': 'Job_8'}\n"
          ]
        }
      ],
      "source": [
        "def people_1():\n",
        "    for i in range(1, 6): \n",
        "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 25 + i, \"City\": \"City_A\"}\n",
        "\n",
        "for person in people_1():\n",
        "         print(person)\n",
        "\n",
        "def people_2():\n",
        "    for i in range(3, 9):\n",
        "         yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 30 + i, \"City\": \"City_B\", \"Occupation\": f\"Job_{i}\"}\n",
        "\n",
        "for person in people_2():\n",
        "     print(person)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. Load the first generator and calculate the sum of ages of all people. Make sure to only load it once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MoaQcdLBEk6",
        "outputId": "d2b93dc1-d83f-44ea-aeff-fdf51d75f7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ID': 1, 'Name': 'Person_1', 'Age': 26, 'City': 'City_A'}\n",
            "{'ID': 2, 'Name': 'Person_2', 'Age': 27, 'City': 'City_A'}\n",
            "{'ID': 3, 'Name': 'Person_3', 'Age': 28, 'City': 'City_A'}\n",
            "{'ID': 4, 'Name': 'Person_4', 'Age': 29, 'City': 'City_A'}\n",
            "{'ID': 5, 'Name': 'Person_5', 'Age': 30, 'City': 'City_A'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LoadInfo(pipeline=<dlt.pipeline.pipeline.Pipeline object at 0x152fa3d50>, metrics={'1708011485.851731': [{'started_at': DateTime(2024, 2, 15, 15, 38, 6, 186965, tzinfo=Timezone('UTC')), 'finished_at': DateTime(2024, 2, 15, 15, 38, 6, 349070, tzinfo=Timezone('UTC'))}]}, destination_type='dlt.destinations.duckdb', destination_displayable_credentials='duckdb:////Users/juancarlosgarcia/Desktop/DE Zoomcamp 2024/Homework/Workshop - Data Ingestion/dlt_resources/dlt_ipykernel_launcher.duckdb', destination_name='duckdb', environment=None, staging_type=None, staging_name=None, staging_displayable_credentials=None, destination_fingerprint='', dataset_name='people1_pipeline', loads_ids=['1708011485.851731'], load_packages=[LoadPackageInfo(load_id='1708011485.851731', package_path='/Users/juancarlosgarcia/.dlt/pipelines/dlt_ipykernel_launcher/load/loaded/1708011485.851731', state='loaded', schema=Schema dlt_ipykernel_launcher at 5691116368, schema_update={}, completed_at=DateTime(2024, 2, 15, 15, 38, 6, 344146, tzinfo=Timezone('UTC')), jobs={'completed_jobs': [LoadJobInfo(state='completed_jobs', file_path='/Users/juancarlosgarcia/.dlt/pipelines/dlt_ipykernel_launcher/load/loaded/1708011485.851731/completed_jobs/table_people_1.e492a3895f.0.insert_values', file_size=302, created_at=DateTime(2024, 2, 15, 15, 38, 5, 869818, tzinfo=Timezone('UTC')), elapsed=0.47432756423950195, job_file_info=ParsedLoadJobFileName(table_name='table_people_1', file_id='e492a3895f', retry_count=0, file_format='insert_values'), failed_message=None)], 'failed_jobs': [], 'new_jobs': [], 'started_jobs': []})], first_run=False)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dlt\n",
        "import duckdb\n",
        "\n",
        "def people_1():\n",
        "    for i in range(1, 6): \n",
        "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 25 + i, \"City\": \"City_A\"}\n",
        "\n",
        "for person in people_1():\n",
        "         print(person)\n",
        "\n",
        "\n",
        "# define the connection to load to.\n",
        "# We now use duckdb, but you can switch to Bigquery later\n",
        "people1_pipeline = dlt.pipeline(destination='duckdb', dataset_name='people1_pipeline')\n",
        "\n",
        "\n",
        "#people1_pipeline\n",
        "# run with merge write disposition.\n",
        "# This is so scaffolding is created for the next example,\n",
        "# where we look at merging data\n",
        "\n",
        "#load data pipeline\n",
        "people1_pipeline.run(people_1(),\n",
        "                 table_name='table_people_1',\n",
        "                 write_disposition=\"replace\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtdTIm4fvQCN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded tables: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "┌─────────────────────┐\n",
              "│        name         │\n",
              "│       varchar       │\n",
              "├─────────────────────┤\n",
              "│ _dlt_loads          │\n",
              "│ _dlt_pipeline_state │\n",
              "│ _dlt_version        │\n",
              "│ table_people1       │\n",
              "│ table_people_1      │\n",
              "└─────────────────────┘"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " Sum of all people ages\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ages_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ages_sum\n",
              "0     140.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "conn = duckdb.connect(f\"{people1_pipeline.pipeline_name}.duckdb\")\n",
        "\n",
        "# loading table\n",
        "conn.sql(f\"SET search_path = '{people1_pipeline.dataset_name}'\")\n",
        "print('Loaded tables: ')\n",
        "display(conn.sql(\"show tables\"))\n",
        "\n",
        "## load the first generator and calculate the sum of all people ages\n",
        "print(\"\\n\\n\\n Sum of all people ages\")\n",
        "sum_ages_q1 = conn.sql(\"SELECT sum(age) As ages_sum FROM table_people_1\").df()\n",
        "display(sum_ages_q1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2 - Append the second generator to the same table as the first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoadInfo(pipeline=<dlt.pipeline.pipeline.Pipeline object at 0x152fa3d50>, metrics={'1708011534.524779': [{'started_at': DateTime(2024, 2, 15, 15, 38, 54, 880811, tzinfo=Timezone('UTC')), 'finished_at': DateTime(2024, 2, 15, 15, 38, 55, 63934, tzinfo=Timezone('UTC'))}]}, destination_type='dlt.destinations.duckdb', destination_displayable_credentials='duckdb:////Users/juancarlosgarcia/Desktop/DE Zoomcamp 2024/Homework/Workshop - Data Ingestion/dlt_resources/dlt_ipykernel_launcher.duckdb', destination_name='duckdb', environment=None, staging_type=None, staging_name=None, staging_displayable_credentials=None, destination_fingerprint='', dataset_name='people1_pipeline', loads_ids=['1708011534.524779'], load_packages=[LoadPackageInfo(load_id='1708011534.524779', package_path='/Users/juancarlosgarcia/.dlt/pipelines/dlt_ipykernel_launcher/load/loaded/1708011534.524779', state='loaded', schema=Schema dlt_ipykernel_launcher at 5680324752, schema_update={}, completed_at=DateTime(2024, 2, 15, 15, 38, 55, 58116, tzinfo=Timezone('UTC')), jobs={'completed_jobs': [LoadJobInfo(state='completed_jobs', file_path='/Users/juancarlosgarcia/.dlt/pipelines/dlt_ipykernel_launcher/load/loaded/1708011534.524779/completed_jobs/table_people_1.1654c14980.0.insert_values', file_size=333, created_at=DateTime(2024, 2, 15, 15, 38, 54, 548561, tzinfo=Timezone('UTC')), elapsed=0.5095546245574951, job_file_info=ParsedLoadJobFileName(table_name='table_people_1', file_id='1654c14980', retry_count=0, file_format='insert_values'), failed_message=None)], 'failed_jobs': [], 'new_jobs': [], 'started_jobs': []})], first_run=False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load data pipeline\n",
        "people1_pipeline.run(people_2(),\n",
        "                 table_name='table_people_1',\n",
        "                 write_disposition=\"append\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3- After correctly appending the data, calculate the sum of all ages of people."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "┌─────────┐\n",
              "│ sum_age │\n",
              "│ int128  │\n",
              "├─────────┤\n",
              "│     353 │\n",
              "└─────────┘"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Question 3s\n",
        "sum_ages_q3= conn.sql(\"SELECT sum(age) AS sum_age FROM table_people_1\")\n",
        "display(sum_ages_q3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY4cFAWOSwN1"
      },
      "source": [
        "# 3. Merge a generator\n",
        "\n",
        "Re-use the generators from Exercise 2.\n",
        "\n",
        "A table's primary key needs to be created from the start, so load your data to a new table with primary key ID.\n",
        "\n",
        "Load your first generator first, and then load the second one with merge. Since they have overlapping IDs, some of the records from the first load should be replaced by the ones from the second load.\n",
        "\n",
        "After loading, you should have a total of 8 records, and ID 3 should have age 33.\n",
        "\n",
        "Question: **Calculate the sum of ages of all the people loaded as described above.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKB2GTB9oVjr"
      },
      "source": [
        "# Solution: First make sure that the following modules are installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTVvtyqrfVNq"
      },
      "outputs": [],
      "source": [
        "#Install the dependencies\n",
        "%%capture\n",
        "!pip install dlt[duckdb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "┌─────────┐\n",
              "│ sum_age │\n",
              "│ int128  │\n",
              "├─────────┤\n",
              "│     266 │\n",
              "└─────────┘"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load table 1\n",
        "people1_pipeline.run(people_1(),\n",
        "                    table_name='table_people_1',\n",
        "                    write_disposition=\"replace\")\n",
        "\n",
        "#load table 2 using merge and primery key [id]\n",
        "people1_pipeline.run(people_2(),\n",
        "                    table_name='table_people_1',\n",
        "                    write_disposition=\"merge\",\n",
        "                    primary_key=\"id\")\n",
        "sum_ages_q4 = conn.sql(\"SELECT sum(age) AS sum_age FROM table_people_1\")\n",
        "display(sum_ages_q4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoTJu4kbGG0z"
      },
      "source": [
        "Questions? difficulties? We are here to help.\n",
        "- DTC data engineering course channel: https://datatalks-club.slack.com/archives/C01FABYF2RG\n",
        "- dlt's DTC cohort channel: https://dlthub-community.slack.com/archives/C06GAEX2VNX"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
